{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis with `sktime`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we analyze (multivariate) time series data with the \n",
    "[`sktime`](https://github.com/sktime/sktime) toolbox. \n",
    "\n",
    "In our context, we work with **event-based** time series data from Durst's printers. \n",
    "Such data has essentially four columns:\n",
    "\n",
    "- `time` representing the time index,\n",
    "- `printer_id` representing a specific printer,\n",
    "- `sensor_id` representing a certain sensor/variable, and\n",
    "- `signal_value` representing the value of a specific `sensor_id` at a certain `time` of \n",
    "`printer_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV files store the data of a specific printer. The CSV choice is arbitrary.\n",
    "\n",
    "In the next cell we:\n",
    "\n",
    "1. read a CSV file with an event-based time series as a `pandas.DataFrame` and store it in a \n",
    "variable called `df`,\n",
    "2. print `df`'s first 10 entries/rows, and\n",
    "3. print `df`'s shape (i.e., a pair containing the number of rows and columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     time  printer_id  sensor_id  signal_value\n",
      "0  2020-09-25 17:36:30+02         565         20         33.50\n",
      "1  2020-09-24 15:46:15+02         565         20         40.80\n",
      "2  2020-09-24 15:23:23+02         565         20         42.50\n",
      "3  2020-09-24 15:24:41+02         565         20         42.00\n",
      "4  2020-09-24 15:30:35+02         565         20         41.50\n",
      "5  2020-09-24 15:10:07+02         565         15         40.51\n",
      "6  2020-09-24 15:26:22+02         565         20         42.50\n",
      "7  2020-09-24 15:26:35+02         565         15         40.09\n",
      "8  2020-09-25 17:18:51+02         565         20         33.15\n",
      "9  2020-09-24 15:32:10+02         565         20         42.00\n",
      "(2152090, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1\n",
    "df = pd.read_csv('/home/edu/Dropbox/Work/Bolzano/Durst/Data/printer_unordered_565.csv')\n",
    "# 2\n",
    "print(df.head(10))\n",
    "# 3\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must **pivot** such representation.\n",
    "\n",
    "Pivoting means to \"open\" such row-based representation to a column-wise one \n",
    "having each `sensor_id` as a column, where the rows are indexed \n",
    "by the pair `printer_id` and `time`, which is a `MultiIndex`. \n",
    "\n",
    "The entry $(i,j)$ of such (new) DataFrame is the `signal_value` of `sensor_id` $= j$ \n",
    "at `time` $=i$ if it exists; otherwise, is a `NaN` entry. \n",
    "\n",
    "Moreover, such entries could contain duplicates and for this reason we need to specify \n",
    "an aggregation function `aggfunc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor_id                           9     10    11    12    13    14    15   \\\n",
      "printer_id time                                                               \n",
      "565        2018-10-02 10:53:51+02   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2018-10-02 10:53:56+02   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2018-10-02 11:34:03+02   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2018-10-02 11:37:21+02   NaN   NaN   NaN   NaN  50.0  50.0  50.0   \n",
      "           2019-02-27 16:54:45+01  50.0  50.0  50.0  50.0  50.0  50.0  50.0   \n",
      "           2019-07-17 15:44:43+02  50.0  50.0  50.0  50.0  50.0  50.0  50.0   \n",
      "           2019-07-17 15:55:39+02   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "           2019-07-17 15:55:40+02   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2019-07-17 16:01:51+02   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2019-07-17 16:02:05+02   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "sensor_id                           16   17   18   ...  663  664  665  666  \\\n",
      "printer_id time                                    ...                       \n",
      "565        2018-10-02 10:53:51+02   NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "           2018-10-02 10:53:56+02   NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "           2018-10-02 11:34:03+02   NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "           2018-10-02 11:37:21+02  50.0  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "           2019-02-27 16:54:45+01  50.0  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "           2019-07-17 15:44:43+02  50.0  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "           2019-07-17 15:55:39+02   0.0  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "           2019-07-17 15:55:40+02   NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "           2019-07-17 16:01:51+02   NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "           2019-07-17 16:02:05+02   NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "\n",
      "sensor_id                          667    668  669  670  671  672  \n",
      "printer_id time                                                    \n",
      "565        2018-10-02 10:53:51+02  NaN    NaN  NaN  NaN  NaN  NaN  \n",
      "           2018-10-02 10:53:56+02  NaN    NaN  NaN  NaN  NaN  NaN  \n",
      "           2018-10-02 11:34:03+02  NaN    NaN  NaN  NaN  NaN  NaN  \n",
      "           2018-10-02 11:37:21+02  NaN    NaN  NaN  NaN  NaN  NaN  \n",
      "           2019-02-27 16:54:45+01  0.0   32.0  NaN  1.0  NaN  NaN  \n",
      "           2019-07-17 15:44:43+02  0.0   32.0  NaN  1.0  NaN  NaN  \n",
      "           2019-07-17 15:55:39+02  1.0  103.0  NaN  0.0  NaN  NaN  \n",
      "           2019-07-17 15:55:40+02  NaN    NaN  NaN  NaN  NaN  NaN  \n",
      "           2019-07-17 16:01:51+02  NaN    NaN  NaN  NaN  NaN  NaN  \n",
      "           2019-07-17 16:02:05+02  NaN    NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[10 rows x 118 columns]\n",
      "(1520284, 118)\n",
      "<class 'pandas.core.indexes.multi.MultiIndex'>\n"
     ]
    }
   ],
   "source": [
    "dfp = df.pivot_table(index=['printer_id', 'time'], columns='sensor_id', values='signal_value', aggfunc='mean')\n",
    "print(dfp.head(10))\n",
    "print(dfp.shape)\n",
    "print(type(dfp.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without further specifications, we convert the DataFrame's second level index type to `DatetimeIndex`. We also use `utc=True` for timezone-related parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor_id                              9     10    11    12    13    14   \\\n",
      "printer_id time                                                            \n",
      "565        2018-10-02 08:53:51+00:00   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2018-10-02 08:53:56+00:00   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2018-10-02 09:34:03+00:00   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2018-10-02 09:37:21+00:00   NaN   NaN   NaN   NaN  50.0  50.0   \n",
      "           2019-02-27 15:54:45+00:00  50.0  50.0  50.0  50.0  50.0  50.0   \n",
      "...                                    ...   ...   ...   ...   ...   ...   \n",
      "           2021-10-04 11:32:10+00:00   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2021-10-04 11:32:11+00:00   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2021-10-04 11:35:31+00:00   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2021-10-04 11:37:11+00:00   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "           2021-10-04 11:38:44+00:00   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "sensor_id                              15    16   17   18   ...  663  664  \\\n",
      "printer_id time                                             ...             \n",
      "565        2018-10-02 08:53:51+00:00   NaN   NaN  NaN  NaN  ...  NaN  NaN   \n",
      "           2018-10-02 08:53:56+00:00   NaN   NaN  NaN  NaN  ...  NaN  NaN   \n",
      "           2018-10-02 09:34:03+00:00   NaN   NaN  NaN  NaN  ...  NaN  NaN   \n",
      "           2018-10-02 09:37:21+00:00  50.0  50.0  NaN  NaN  ...  NaN  NaN   \n",
      "           2019-02-27 15:54:45+00:00  50.0  50.0  NaN  NaN  ...  NaN  NaN   \n",
      "...                                    ...   ...  ...  ...  ...  ...  ...   \n",
      "           2021-10-04 11:32:10+00:00   NaN   NaN  NaN  NaN  ...  NaN  NaN   \n",
      "           2021-10-04 11:32:11+00:00   NaN   NaN  NaN  NaN  ...  NaN  NaN   \n",
      "           2021-10-04 11:35:31+00:00   NaN   NaN  NaN  NaN  ...  NaN  NaN   \n",
      "           2021-10-04 11:37:11+00:00   NaN   NaN  NaN  NaN  ...  NaN  NaN   \n",
      "           2021-10-04 11:38:44+00:00   NaN   NaN  NaN  NaN  ...  NaN  NaN   \n",
      "\n",
      "sensor_id                             665  666  667   668  669  670  671  672  \n",
      "printer_id time                                                                \n",
      "565        2018-10-02 08:53:51+00:00  NaN  NaN  NaN   NaN  NaN  NaN  NaN  NaN  \n",
      "           2018-10-02 08:53:56+00:00  NaN  NaN  NaN   NaN  NaN  NaN  NaN  NaN  \n",
      "           2018-10-02 09:34:03+00:00  NaN  NaN  NaN   NaN  NaN  NaN  NaN  NaN  \n",
      "           2018-10-02 09:37:21+00:00  NaN  NaN  NaN   NaN  NaN  NaN  NaN  NaN  \n",
      "           2019-02-27 15:54:45+00:00  NaN  NaN  0.0  32.0  NaN  1.0  NaN  NaN  \n",
      "...                                   ...  ...  ...   ...  ...  ...  ...  ...  \n",
      "           2021-10-04 11:32:10+00:00  NaN  NaN  NaN   NaN  NaN  NaN  NaN  NaN  \n",
      "           2021-10-04 11:32:11+00:00  NaN  NaN  NaN   NaN  NaN  NaN  NaN  NaN  \n",
      "           2021-10-04 11:35:31+00:00  NaN  NaN  NaN   NaN  NaN  NaN  NaN  NaN  \n",
      "           2021-10-04 11:37:11+00:00  NaN  NaN  NaN   NaN  NaN  NaN  NaN  NaN  \n",
      "           2021-10-04 11:38:44+00:00  NaN  NaN  NaN   NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[1520284 rows x 118 columns]\n",
      "<class 'pandas.core.indexes.multi.MultiIndex'>\n"
     ]
    }
   ],
   "source": [
    "dfp.index = dfp.index.set_levels([dfp.index.levels[0], pd.to_datetime(dfp.index.levels[1], utc=True)])\n",
    "print(dfp)\n",
    "print(type(dfp.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell, we `resample` the time-related data points montly (`M`), and we aggregate such values by computing the `mean` value.\n",
    "\n",
    "Observe that after such an operation, the `printer_id` is lost from the index, and we must restore it to a `MultiIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2018-10-31 00:00:00+00:00', '2018-11-30 00:00:00+00:00',\n",
      "               '2018-12-31 00:00:00+00:00', '2019-01-31 00:00:00+00:00',\n",
      "               '2019-02-28 00:00:00+00:00', '2019-03-31 00:00:00+00:00',\n",
      "               '2019-04-30 00:00:00+00:00', '2019-05-31 00:00:00+00:00',\n",
      "               '2019-06-30 00:00:00+00:00', '2019-07-31 00:00:00+00:00',\n",
      "               '2019-08-31 00:00:00+00:00', '2019-09-30 00:00:00+00:00',\n",
      "               '2019-10-31 00:00:00+00:00', '2019-11-30 00:00:00+00:00',\n",
      "               '2019-12-31 00:00:00+00:00', '2020-01-31 00:00:00+00:00',\n",
      "               '2020-02-29 00:00:00+00:00', '2020-03-31 00:00:00+00:00',\n",
      "               '2020-04-30 00:00:00+00:00', '2020-05-31 00:00:00+00:00',\n",
      "               '2020-06-30 00:00:00+00:00', '2020-07-31 00:00:00+00:00',\n",
      "               '2020-08-31 00:00:00+00:00', '2020-09-30 00:00:00+00:00',\n",
      "               '2020-10-31 00:00:00+00:00', '2020-11-30 00:00:00+00:00',\n",
      "               '2020-12-31 00:00:00+00:00', '2021-01-31 00:00:00+00:00',\n",
      "               '2021-02-28 00:00:00+00:00', '2021-03-31 00:00:00+00:00',\n",
      "               '2021-04-30 00:00:00+00:00', '2021-05-31 00:00:00+00:00',\n",
      "               '2021-06-30 00:00:00+00:00', '2021-07-31 00:00:00+00:00',\n",
      "               '2021-08-31 00:00:00+00:00', '2021-09-30 00:00:00+00:00',\n",
      "               '2021-10-31 00:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='time', freq='M')\n",
      "MultiIndex([('565', '2018-10-31'),\n",
      "            ('565', '2018-11-30'),\n",
      "            ('565', '2018-12-31'),\n",
      "            ('565', '2019-01-31'),\n",
      "            ('565', '2019-02-28'),\n",
      "            ('565', '2019-03-31'),\n",
      "            ('565', '2019-04-30'),\n",
      "            ('565', '2019-05-31'),\n",
      "            ('565', '2019-06-30'),\n",
      "            ('565', '2019-07-31'),\n",
      "            ('565', '2019-08-31'),\n",
      "            ('565', '2019-09-30'),\n",
      "            ('565', '2019-10-31'),\n",
      "            ('565', '2019-11-30'),\n",
      "            ('565', '2019-12-31'),\n",
      "            ('565', '2020-01-31'),\n",
      "            ('565', '2020-02-29'),\n",
      "            ('565', '2020-03-31'),\n",
      "            ('565', '2020-04-30'),\n",
      "            ('565', '2020-05-31'),\n",
      "            ('565', '2020-06-30'),\n",
      "            ('565', '2020-07-31'),\n",
      "            ('565', '2020-08-31'),\n",
      "            ('565', '2020-09-30'),\n",
      "            ('565', '2020-10-31'),\n",
      "            ('565', '2020-11-30'),\n",
      "            ('565', '2020-12-31'),\n",
      "            ('565', '2021-01-31'),\n",
      "            ('565', '2021-02-28'),\n",
      "            ('565', '2021-03-31'),\n",
      "            ('565', '2021-04-30'),\n",
      "            ('565', '2021-05-31'),\n",
      "            ('565', '2021-06-30'),\n",
      "            ('565', '2021-07-31'),\n",
      "            ('565', '2021-08-31'),\n",
      "            ('565', '2021-09-30'),\n",
      "            ('565', '2021-10-31')],\n",
      "           names=['printer_id', 'time'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>663</th>\n",
       "      <th>664</th>\n",
       "      <th>665</th>\n",
       "      <th>666</th>\n",
       "      <th>667</th>\n",
       "      <th>668</th>\n",
       "      <th>669</th>\n",
       "      <th>670</th>\n",
       "      <th>671</th>\n",
       "      <th>672</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>printer_id</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">565</th>\n",
       "      <th>2018-10-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "sensor_id               9     10    11    12    13    14    15    16   17   \\\n",
       "printer_id time                                                              \n",
       "565        2018-10-31   NaN   NaN   NaN   NaN  50.0  50.0  50.0  50.0  NaN   \n",
       "           2018-11-30   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "           2018-12-31   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "           2019-01-31   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "           2019-02-28  50.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  NaN   \n",
       "\n",
       "sensor_id              18   ...  663  664  665  666  667   668  669  670  671  \\\n",
       "printer_id time             ...                                                 \n",
       "565        2018-10-31  NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN  NaN  NaN  NaN   \n",
       "           2018-11-30  NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN  NaN  NaN  NaN   \n",
       "           2018-12-31  NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN  NaN  NaN  NaN   \n",
       "           2019-01-31  NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN  NaN  NaN  NaN   \n",
       "           2019-02-28  NaN  ...  NaN  NaN  NaN  NaN  0.0  32.0  NaN  1.0  NaN   \n",
       "\n",
       "sensor_id              672  \n",
       "printer_id time             \n",
       "565        2018-10-31  NaN  \n",
       "           2018-11-30  NaN  \n",
       "           2018-12-31  NaN  \n",
       "           2019-01-31  NaN  \n",
       "           2019-02-28  NaN  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr = dfp.resample('M', level='time').mean()\n",
    "\n",
    "print(dfr.index)\n",
    "\n",
    "dfr.set_index(pd.MultiIndex.from_product([[\"565\"], dfr.index.values], names=[\"printer_id\", \"time\"]), inplace=True) #.set_index([pd.Index([\"564\"]), 'time'])\n",
    "\n",
    "print(dfr.index)\n",
    "\n",
    "dfr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating the workflow\n",
    "\n",
    "Putting all together, we can define a function that automatically reads many CSV files and builds a dataset, also known as panel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "printers = [565, 574, 628, 679, 686]\n",
    "\n",
    "\n",
    "def build_panel(printers, freq='M', pivot_aggfn='mean'): # , resample_aggfn='mean'):\n",
    "    panel = pd.DataFrame()\n",
    "    for printer_id in printers:\n",
    "        # 1. read csv\n",
    "        df = pd.read_csv(f'/home/edu/Dropbox/Work/Bolzano/Durst/Data/printer_unordered_{ printer_id }.csv')\n",
    "        # 2. pivot table\n",
    "        dfp = df.pivot_table(index=['printer_id', 'time'], columns='sensor_id', values='signal_value', aggfunc=pivot_aggfn)\n",
    "        # 3. convert time index to datetime\n",
    "        dfp.index = dfp.index.set_levels([dfp.index.levels[0], pd.to_datetime(dfp.index.levels[1], utc=True)])\n",
    "        # 4. resample\n",
    "        dfr = dfp.resample(freq, level='time').mean()\n",
    "        # 5. set multiindex\n",
    "        dfr.set_index(pd.MultiIndex.from_product([[f'{ printer_id }'], dfr.index.values], names=[\"printer_id\", \"time\"]), inplace=True)\n",
    "        # 6. concatenate the result\n",
    "        panel = pd.concat([panel, dfr])\n",
    "\n",
    "    return panel\n",
    "\n",
    "panel = build_panel(printers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect a particular instance/multivariate time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['565', '574', '628', '679', '686']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37, 118)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/53927460/select-rows-in-pandas-multiindex-dataframe\n",
    "# panel.loc[['565']]\n",
    "\n",
    "print([idx for idx in panel.index.levels[0]])\n",
    "\n",
    "panel.xs('565', level=0, axis=0, drop_level=False).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with `sktime`\n",
    "\n",
    "The package has many, what they call, **estimators**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARDL</td>\n",
       "      <td>&lt;class 'sktime.forecasting.ardl.ARDL'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>&lt;class 'sktime.forecasting.arima.ARIMA'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AggrDist</td>\n",
       "      <td>&lt;class 'sktime.dists_kernels.compose_tab_to_pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggregator</td>\n",
       "      <td>&lt;class 'sktime.transformations.hierarchical.ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AlignerDTW</td>\n",
       "      <td>&lt;class 'sktime.alignment.dtw_python.AlignerDTW'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>WeightedEnsembleClassifier</td>\n",
       "      <td>&lt;class 'sktime.classification.ensemble._weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>WhiteNoiseAugmenter</td>\n",
       "      <td>&lt;class 'sktime.transformations.series.augmente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>WindowSummarizer</td>\n",
       "      <td>&lt;class 'sktime.transformations.series.summariz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>YfromX</td>\n",
       "      <td>&lt;class 'sktime.forecasting.compose._reduce.Yfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>YtoX</td>\n",
       "      <td>&lt;class 'sktime.transformations.compose._ytox.Y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0                          ARDL   \n",
       "1                         ARIMA   \n",
       "2                      AggrDist   \n",
       "3                    Aggregator   \n",
       "4                    AlignerDTW   \n",
       "..                          ...   \n",
       "324  WeightedEnsembleClassifier   \n",
       "325         WhiteNoiseAugmenter   \n",
       "326            WindowSummarizer   \n",
       "327                      YfromX   \n",
       "328                        YtoX   \n",
       "\n",
       "                                                object  \n",
       "0               <class 'sktime.forecasting.ardl.ARDL'>  \n",
       "1             <class 'sktime.forecasting.arima.ARIMA'>  \n",
       "2    <class 'sktime.dists_kernels.compose_tab_to_pa...  \n",
       "3    <class 'sktime.transformations.hierarchical.ag...  \n",
       "4     <class 'sktime.alignment.dtw_python.AlignerDTW'>  \n",
       "..                                                 ...  \n",
       "324  <class 'sktime.classification.ensemble._weight...  \n",
       "325  <class 'sktime.transformations.series.augmente...  \n",
       "326  <class 'sktime.transformations.series.summariz...  \n",
       "327  <class 'sktime.forecasting.compose._reduce.Yfr...  \n",
       "328  <class 'sktime.transformations.compose._ytox.Y...  \n",
       "\n",
       "[329 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the list is quite long, and we need a better way of viewing it. \n",
    "\n",
    "We can filter, for example, only the **transformer**s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scitype:transform-input': 'Series',\n",
       " 'scitype:transform-output': 'Series',\n",
       " 'scitype:transform-labels': 'None',\n",
       " 'scitype:instancewise': True,\n",
       " 'X_inner_mtype': ['pd.Series',\n",
       "  'pd.DataFrame',\n",
       "  'pd-multiindex',\n",
       "  'pd_multiindex_hier'],\n",
       " 'y_inner_mtype': 'None',\n",
       " 'capability:inverse_transform': False,\n",
       " 'skip-inverse-transform': True,\n",
       " 'univariate-only': False,\n",
       " 'handles-missing-data': False,\n",
       " 'X-y-must-have-same-index': False,\n",
       " 'fit_is_empty': True,\n",
       " 'transform-returns-same-time-index': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dict([ (tag,value) for tag, value in all_estimators('transformer')[0][1]._tags.items() ]) # , as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` also offers a functionality for inspecting the **tags**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>scitype</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X-y-must-have-same-index</td>\n",
       "      <td>[forecaster, regressor]</td>\n",
       "      <td>bool</td>\n",
       "      <td>do X/y in fit/update and X/fh in predict have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_inner_mtype</td>\n",
       "      <td>[clusterer, forecaster, transformer, transform...</td>\n",
       "      <td>(list, [pd.Series, pd.DataFrame, np.array, nes...</td>\n",
       "      <td>which machine type(s) is the internal _fit/_pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alignment_type</td>\n",
       "      <td>aligner</td>\n",
       "      <td>(str, [full, partial])</td>\n",
       "      <td>does aligner produce a full or partial alignment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>approx_energy_spl</td>\n",
       "      <td>distribution</td>\n",
       "      <td>int</td>\n",
       "      <td>sample size used in approximating generative e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>approx_mean_spl</td>\n",
       "      <td>distribution</td>\n",
       "      <td>int</td>\n",
       "      <td>sample size used in approximating generative m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>symmetric</td>\n",
       "      <td>[transformer-pairwise, transformer-pairwise-pa...</td>\n",
       "      <td>bool</td>\n",
       "      <td>is the transformer symmetric, i.e., t(x,y)=t(y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>transform-returns-same-time-index</td>\n",
       "      <td>transformer</td>\n",
       "      <td>bool</td>\n",
       "      <td>does transform return same time index as input?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>univariate-metric</td>\n",
       "      <td>metric</td>\n",
       "      <td>bool</td>\n",
       "      <td>Does the metric only work on univariate y data?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>univariate-only</td>\n",
       "      <td>transformer</td>\n",
       "      <td>bool</td>\n",
       "      <td>can transformer handle multivariate series? Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>y_inner_mtype</td>\n",
       "      <td>[forecaster, transformer]</td>\n",
       "      <td>(list, [pd.Series, pd.DataFrame, np.array, nes...</td>\n",
       "      <td>which machine type(s) is the internal _fit/_pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  \\\n",
       "0            X-y-must-have-same-index   \n",
       "1                       X_inner_mtype   \n",
       "2                      alignment_type   \n",
       "3                   approx_energy_spl   \n",
       "4                     approx_mean_spl   \n",
       "..                                ...   \n",
       "57                          symmetric   \n",
       "58  transform-returns-same-time-index   \n",
       "59                  univariate-metric   \n",
       "60                    univariate-only   \n",
       "61                      y_inner_mtype   \n",
       "\n",
       "                                              scitype  \\\n",
       "0                             [forecaster, regressor]   \n",
       "1   [clusterer, forecaster, transformer, transform...   \n",
       "2                                             aligner   \n",
       "3                                        distribution   \n",
       "4                                        distribution   \n",
       "..                                                ...   \n",
       "57  [transformer-pairwise, transformer-pairwise-pa...   \n",
       "58                                        transformer   \n",
       "59                                             metric   \n",
       "60                                        transformer   \n",
       "61                          [forecaster, transformer]   \n",
       "\n",
       "                                                 type  \\\n",
       "0                                                bool   \n",
       "1   (list, [pd.Series, pd.DataFrame, np.array, nes...   \n",
       "2                              (str, [full, partial])   \n",
       "3                                                 int   \n",
       "4                                                 int   \n",
       "..                                                ...   \n",
       "57                                               bool   \n",
       "58                                               bool   \n",
       "59                                               bool   \n",
       "60                                               bool   \n",
       "61  (list, [pd.Series, pd.DataFrame, np.array, nes...   \n",
       "\n",
       "                                          description  \n",
       "0   do X/y in fit/update and X/fh in predict have ...  \n",
       "1   which machine type(s) is the internal _fit/_pr...  \n",
       "2    does aligner produce a full or partial alignment  \n",
       "3   sample size used in approximating generative e...  \n",
       "4   sample size used in approximating generative m...  \n",
       "..                                                ...  \n",
       "57  is the transformer symmetric, i.e., t(x,y)=t(y...  \n",
       "58    does transform return same time index as input?  \n",
       "59    Does the metric only work on univariate y data?  \n",
       "60  can transformer handle multivariate series? Tr...  \n",
       "61  which machine type(s) is the internal _fit/_pr...  \n",
       "\n",
       "[62 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.registry import all_tags\n",
    "\n",
    "all_tags(as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use such tags to filter the estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_estimators' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/edu/.python/inest/time_series_analysis_with_sktime.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/edu/.python/inest/time_series_analysis_with_sktime.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m all_estimators(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edu/.python/inest/time_series_analysis_with_sktime.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtransformer\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edu/.python/inest/time_series_analysis_with_sktime.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     filter_tags\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39munivariate-only\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m},\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edu/.python/inest/time_series_analysis_with_sktime.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     return_names\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edu/.python/inest/time_series_analysis_with_sktime.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_estimators' is not defined"
     ]
    }
   ],
   "source": [
    "all_estimators(\n",
    "    'transformer',\n",
    "    filter_tags={'univariate-only': True},\n",
    "    return_names=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scitype:transform-input': 'Series',\n",
       " 'scitype:transform-output': 'Series',\n",
       " 'scitype:instancewise': True,\n",
       " 'X_inner_mtype': ['pd.DataFrame'],\n",
       " 'y_inner_mtype': 'None',\n",
       " 'fit_is_empty': False,\n",
       " 'handles-missing-data': True,\n",
       " 'skip-inverse-transform': True,\n",
       " 'capability:inverse_transform': True,\n",
       " 'univariate-only': False,\n",
       " 'capability:missing_values:removes': True,\n",
       " 'remember_data': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.transformations.series.impute import Imputer\n",
    "from sktime.transformations.panel.dictionary_based import PAA\n",
    "# from sktime.transformations.series.summarize import SummaryTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "imputer = Imputer()\n",
    "paa = PAA(4)\n",
    "\n",
    "pipe = imputer * paa\n",
    "\n",
    "# pipe.fit(panel)\n",
    "\n",
    "# pipe.transform(panel)\n",
    "\n",
    "Imputer()._tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self', 'method', 'random_state', 'value', 'forecaster', 'missing_values']\n",
      "[<Parameter \"self\">, <Parameter \"method='drift'\">, <Parameter \"random_state=None\">, <Parameter \"value=None\">, <Parameter \"forecaster=None\">, <Parameter \"missing_values=None\">]\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "# from sktime.transformations.series.impute import Imputer\n",
    "import sktime\n",
    "\n",
    "print(list(inspect.signature(sktime.transformations.series.impute.Imputer.__init__).parameters.keys()))\n",
    "print(list(inspect.signature(sktime.transformations.series.impute.Imputer.__init__).parameters.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
